{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import re \n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "from distutils.dir_util import copy_tree\n",
    "from pathlib import Path\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# rootDir = os.getcwd()\n",
    "# rootDir = r'C:\\Users\\Laxman\\Desktop\\autoWoodSDA\\Auto-WoodSDA'\n",
    "rootDir = r'/Users/laxmandahal/Desktop/UCLA/Phd/Research/woodSDA/autoWoodSDA_public'\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_colwidth', 100)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing source code from the design module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(os.path.join(rootDir, *['Codes','designModule']))\n",
    "sys.path.append(os.path.join(rootDir, *['Codes','designModule']))\n",
    "\n",
    "\n",
    "from FinalShearWallDesign_allFloors import FinalShearWallDesign\n",
    "from StiffnessBasedDesign import RDADesignIterationClass\n",
    "\n",
    "## setting up directories and folders for I/O purposes\n",
    "# Utility function directory \n",
    "UtilDirectory = os.path.join(rootDir, *['Codes','modelingModule'])\n",
    "# Base directory is the main directory that models, model inputs and utility directory stores\n",
    "# BaseDirectory = rootDir\n",
    "# Model directory is where you want to store your model\n",
    "ModelDirectory = os.path.join(rootDir, 'BuildingModels')\n",
    "# If there is no model directory, create one\n",
    "Path(ModelDirectory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# DB directory is where you store Database.csv (for steel section)\n",
    "DBDirecctory = UtilDirectory\n",
    "\n",
    "resultDirectory = os.path.join(rootDir, 'Results')\n",
    "# create one if it already doesnot exist\n",
    "Path(resultDirectory).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:Design Module:\n",
    "The design module designs the building per input specifications and outputs design summary with shear wall schedule for each story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.072130918502808 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "caseID = 'MFD6B'\n",
    "# caseID = BuildingList[0]\n",
    "basedirectory = os.path.join(rootDir, *['BuildingInfo', caseID])\n",
    "numFloors = 4\n",
    " \n",
    "direction = ['X', 'X', 'X', \n",
    "             'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y']\n",
    "wall_line_name = ['gridA', 'gridB', 'gridC',\n",
    "                  'grid1', 'grid2','grid3','grid4','grid5','grid6', 'grid7']\n",
    "numWallsPerLine = [4, 4, 4,\n",
    "                  2, 2, 4, 2, 4, 2, 2]\n",
    "counter = 0\n",
    "\n",
    "rda = RDADesignIterationClass(caseID, basedirectory, direction,numWallsPerLine, counter, wall_line_name,\n",
    "                              designScheme='ASD',\n",
    "                              Ss=1.85, S1=0.8,\n",
    "                              weight_factor=1, seismic_design_level='Extreme', mat_ext_int='Stucco_GWB')\n",
    "\n",
    "# rda.maindf\n",
    "# rda.maindf.to_csv(os.path.join(resultDirectory, \"FinalDesignOutput.csv\"))\n",
    "stop = time.time()\n",
    "print( stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Shear Wall Assembly</th>\n",
       "      <th>Ga(k/in)</th>\n",
       "      <th>level</th>\n",
       "      <th>ASD(klf)</th>\n",
       "      <th>Drift(in)</th>\n",
       "      <th>D/C Ratio</th>\n",
       "      <th>OpenSees Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">swDesign_gridA_wall1</th>\n",
       "      <th>0</th>\n",
       "      <td>Use 1/2in GWB with 5d cooler nails @ 7in o.c. ...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.752068</td>\n",
       "      <td>0.745203</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Use 7/16in WSP on 1 side with 8d nails @ 6o.c....</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.598134</td>\n",
       "      <td>0.931504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Use 7/16in WSP on 1 side with 8d nails @ 3o.c....</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.632109</td>\n",
       "      <td>0.993605</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Use 15/32in WSP on 1 side with 10d nails @ 2o....</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.614523</td>\n",
       "      <td>0.824056</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swDesign_gridA_wall2</th>\n",
       "      <th>0</th>\n",
       "      <td>Use 1/2in GWB with 5d cooler nails @ 7in o.c. ...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.746609</td>\n",
       "      <td>0.745338</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swDesign_grid7_wall1</th>\n",
       "      <th>3</th>\n",
       "      <td>Use 7/16in WSP on 1 side with 8d nails @ 2o.c....</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.740948</td>\n",
       "      <td>0.976288</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">swDesign_grid7_wall2</th>\n",
       "      <th>0</th>\n",
       "      <td>Use 1/2in GWB with 5d cooler nails @ 7in o.c. ...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.682719</td>\n",
       "      <td>0.670750</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Use 7/16in WSP on 1 side with 8d nails @ 6o.c....</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.838438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Use 7/16in WSP on 1 side with 8d nails @ 3o.c....</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.894334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Use 7/16in WSP on 1 side with 8d nails @ 2o.c....</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.740948</td>\n",
       "      <td>0.976288</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Shear Wall Assembly  \\\n",
       "swDesign_gridA_wall1 0  Use 1/2in GWB with 5d cooler nails @ 7in o.c. ...   \n",
       "                     1  Use 7/16in WSP on 1 side with 8d nails @ 6o.c....   \n",
       "                     2  Use 7/16in WSP on 1 side with 8d nails @ 3o.c....   \n",
       "                     3  Use 15/32in WSP on 1 side with 10d nails @ 2o....   \n",
       "swDesign_gridA_wall2 0  Use 1/2in GWB with 5d cooler nails @ 7in o.c. ...   \n",
       "...                                                                   ...   \n",
       "swDesign_grid7_wall1 3  Use 7/16in WSP on 1 side with 8d nails @ 2o.c....   \n",
       "swDesign_grid7_wall2 0  Use 1/2in GWB with 5d cooler nails @ 7in o.c. ...   \n",
       "                     1  Use 7/16in WSP on 1 side with 8d nails @ 6o.c....   \n",
       "                     2  Use 7/16in WSP on 1 side with 8d nails @ 3o.c....   \n",
       "                     3  Use 7/16in WSP on 1 side with 8d nails @ 2o.c....   \n",
       "\n",
       "                        Ga(k/in)  level  ASD(klf)  Drift(in)  D/C Ratio  \\\n",
       "swDesign_gridA_wall1 0       5.2      4     0.100   0.752068   0.745203   \n",
       "                     1      15.0      3     0.240   0.598134   0.931504   \n",
       "                     2      28.0      2     0.450   0.632109   0.993605   \n",
       "                     3      52.0      1     0.770   0.614523   0.824056   \n",
       "swDesign_gridA_wall2 0       5.2      4     0.100   0.746609   0.745338   \n",
       "...                          ...    ...       ...        ...        ...   \n",
       "swDesign_grid7_wall1 3      42.0      1     0.585   0.740948   0.976288   \n",
       "swDesign_grid7_wall2 0       5.2      4     0.100   0.682719   0.670750   \n",
       "                     1      15.0      3     0.240   0.753968   0.838438   \n",
       "                     2      28.0      2     0.450   0.738485   0.894334   \n",
       "                     3      42.0      1     0.585   0.740948   0.976288   \n",
       "\n",
       "                        OpenSees Tag  \n",
       "swDesign_gridA_wall1 0            14  \n",
       "                     1             1  \n",
       "                     2             2  \n",
       "                     3            11  \n",
       "swDesign_gridA_wall2 0            14  \n",
       "...                              ...  \n",
       "swDesign_grid7_wall1 3             5  \n",
       "swDesign_grid7_wall2 0            14  \n",
       "                     1             1  \n",
       "                     2             2  \n",
       "                     3             5  \n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rda.maindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "caseID = 'MFD6B'\n",
    "# caseID = BuildingList[0]\n",
    "basedirectory = os.path.join(rootDir, *['BuildingInfo', caseID])\n",
    "numFloors = 4\n",
    " \n",
    "direction = ['X', 'X', 'X', \n",
    "             'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y']\n",
    "wall_line_name = ['gridA', 'gridB', 'gridC',\n",
    "                  'grid1', 'grid2','grid3','grid4','grid5','grid6', 'grid7']\n",
    "numWallsPerLine = [4, 4, 4,\n",
    "                  2, 2, 4, 2, 4, 2, 2]\n",
    "counter = 0\n",
    "\n",
    "rda = RDADesignIterationClass(caseID, basedirectory, direction,numWallsPerLine, counter, wall_line_name,\n",
    "                              designScheme='ASD',\n",
    "                              weight_factor=1, seismic_design_level='Extreme', mat_ext_int='Stucco_GWB')\n",
    "\n",
    "# rda.maindf\n",
    "# rda.maindf.to_csv(os.path.join(resultDirectory, \"FinalDesignOutput.csv\"))\n",
    "stop = time.time()\n",
    "print( stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rda.maindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psutil;\n",
    "# print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2, 'MB memory required')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Modeling Module\n",
    "Implement the modeling module to genere a suite of OpenSees models. Three individual models are created for Modal, Pushover, and Dyanmic analysis. The flag ___RunPushoverSwitch___ automatically runs the pushover analysis after creating the required tcl files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(rootDir, *['Codes','modelingModule']))\n",
    "from BuildingModelClass import BuildingModel\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Generate eigen analysis, pushover analysis and dynamic analysis models\n",
    "design_level = 'Extreme'\n",
    "\n",
    "InfoDirectory = os.path.join(rootDir, *['BuildingInfo', caseID])\n",
    "ModelClass = BuildingModel(caseID, InfoDirectory, seismic_design_level = design_level)\n",
    "\n",
    "# alternatively, one can choose to read inputs from json \n",
    "ModelClass.read_in_txt_inputs(caseID, InfoDirectory)\n",
    "\n",
    "# if os.path.isdir(ModelDirectory+'/%s'%BuildingList[i]) != True:\n",
    "#     os.chdir(ModelDirectory)\n",
    "#     os.mkdir('%s'%BuildingList[i])\n",
    "\n",
    "os.chdir(ModelDirectory+'/%s'%caseID)\n",
    "period = generateModalAnalysisModel(ModelClass.ID, ModelClass, rootDir)\n",
    "# Turn off RunPushoverSwitch to speed up the model creation \n",
    "generatePushoverAnalysisModel(ModelClass.ID, ModelClass, rootDir,\n",
    "                           GenerateModelSwitch = True, RunPushoverSwitch = True)\n",
    "generateDynamicAnalysisModel(ModelClass.ID, ModelClass, rootDir, period,\n",
    "                           GenerateModelSwitch = True)\n",
    "print(period)\n",
    "\n",
    "finish = time.time()\n",
    "print((finish - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BuildingList = [caseID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(rootDir, *['Codes', 'PostProcessing']))\n",
    "\n",
    "import ExtractMaxEDP as extractedps\n",
    "import ExtractPushoverData as epd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigen Analysis summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenDirectory = os.path.join(rootDir, *['BuildingModels',BuildingList[0],'EigenValueAnalysis','Analysis_Results'])\n",
    "periods = extractedps.ExtractPeriod(eigenDirectory)\n",
    "periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear static pushover curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = np.loadtxt(os.path.join(rootDir, *['BuildingInfo',BuildingList[0],'Loads','floorWeights.txt']))\n",
    "SeismicWeight = np.sum(wt)\n",
    "\n",
    "BaseDirectory = os.path.join(rootDir, *['BuildingModels',BuildingList[0]])\n",
    "\n",
    "PushoverX_rigid = epd.pushoverdata(BaseDirectory+ '\\PushoverAnalysis\\\\', 'X', 'roof', SeismicWeight, numFloors)\n",
    "PushoverResultsX_rigid = epd.extractpushoverpoints(PushoverX_rigid)\n",
    "\n",
    "PushoverY_rigid = epd.pushoverdata(BaseDirectory+ '\\PushoverAnalysis\\\\', 'Z', 'roof', SeismicWeight, numFloors)\n",
    "PushoverResultsY_rigid = epd.extractpushoverpoints(PushoverY_rigid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PushoverX = epd.pushoverdata(BaseDirectory+ '\\PushoverAnalysis\\\\', 'X', 'roof', SeismicWeight, numFloors)\n",
    "PushoverResultsX = epd.extractpushoverpoints(PushoverX)\n",
    "\n",
    "PushoverResultsX = np.append(np.array(PushoverResultsX), PushoverX[1][-1])\n",
    "\n",
    "PushoverY = epd.pushoverdata(BaseDirectory+ '\\PushoverAnalysis\\\\', 'Z', 'roof', SeismicWeight, numFloors)\n",
    "PushoverResultsY = epd.extractpushoverpoints(PushoverY)\n",
    "\n",
    "PushoverResultsY = np.append(np.array(PushoverResultsY), PushoverY[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(PushoverX[1],PushoverX[0],label = 'X-dir')\n",
    "plt.plot(PushoverY[1],PushoverY[0],label = 'Z-dir')\n",
    "\n",
    "plt.scatter(PushoverResultsX[1],PushoverResultsX[0])\n",
    "plt.scatter(PushoverResultsX[2], 0.8*PushoverResultsX[0])\n",
    "\n",
    "plt.scatter(PushoverResultsY[1],PushoverResultsY[0])\n",
    "plt.scatter(PushoverResultsY[2], 0.8*PushoverResultsY[0])\n",
    "\n",
    "plt.xlabel('Roof Drift (%)')\n",
    "plt.ylabel('Normalized Base Shear (V/M)')\n",
    "plt.title(f'Pushover Curve: {caseID}', fontsize = 14)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([PushoverResultsX, PushoverResultsY], \n",
    "                  columns = ['Peak Strength', 'Drift at Peak', 'Drift at 80%Peak', 'Max Drift'],\n",
    "                  index = ['X', 'Y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run dynamic analysis \n",
    "\n",
    "Files required to run dynamic analysis has been created in the previous step, the following code iteratively runs the dynamic analysis upto the specified number of Ground motions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MSA using selected GM records for 5 hazard levels. Location: Boelter Hall\n",
    "Scale_Sa_GM = '0.403 0.975 1.307 1.676 2.237'\n",
    "GM_Num = '50 47 47 48 47'\n",
    "\n",
    "# GM_ID = 1 # GM pair\n",
    "GM_folder = r'GM_sets/BoelterHall'\n",
    "\n",
    "Model_Name = BuildingList[0]\n",
    "\n",
    "\n",
    "# start_ID is tarting index which starts from 1 instead of 0\n",
    "# finish_ID is the total number of GMs in multiple stripe or incremental dynamic analysis\n",
    "# for eg: if you have 10 hazard levels with 22 GM pairs, finish_id should be 10*22 + 1\n",
    "start_ID, finish_ID = 1, 3 # for demonstration I'm running dynamic analysis for 2 ground motion pairs\n",
    "acc_time = 0\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "## following chucks of codes run dynamic analysis for each ground motion pair iteratively\n",
    "# Pairing ID == 1 i.e. apply H1 motion in X and H2 motion in Z\n",
    "for GM_ID in range(start_ID, finish_ID):\n",
    "    s = time.time()\n",
    "    SetupDyamaicAnalysis(ModelDirectory, Scale_Sa_GM, GM_Num, GM_ID, GM_folder, Model_Name, 1)\n",
    "    os.chdir(ModelDirectory)\n",
    "    r = os.system('OpenSees RunDynamic_Single.tcl')\n",
    "    f = time.time()\n",
    "    if not r: \n",
    "        print('Hazard Level %i GM Pair %s with Pairing ID %i has finished successfully in %.3fs!'%(int(GM_ID/50)+1, str(GM_ID-int(GM_ID/50)), 1, f-s))\n",
    "        os.remove('RunDynamic_Single.tcl')\n",
    "        acc_time += (f-s)\n",
    "        #print('Estimate remaining time %.3fs!'%(acc_time/(GM_ID - start_ID)*(finish_ID - GM_ID)))\n",
    "    else: \n",
    "        print('GM Pair %s has failed'%str(GM_ID))\n",
    "        break\n",
    "\n",
    "# Pairing ID == 2 i.e. apply H2 motion in X and H1 motion in Z\n",
    "for GM_ID in range(start_ID, finish_ID):\n",
    "    s = time.time()\n",
    "    SetupDyamaicAnalysis(ModelDirectory, Scale_Sa_GM, GM_Num, GM_ID, GM_folder, Model_Name, 2)\n",
    "    os.chdir(ModelDirectory)\n",
    "    r = os.system('OpenSees RunDynamic_Single.tcl')\n",
    "    f = time.time()\n",
    "    if not r: \n",
    "#         print('Hazard Level %i GM Pair %s with Pairing ID %i has finished successfully in %.3fs!'%(int(GM_ID/22)+1, str(GM_ID-int(GM_ID/22)), 2, f-s))\n",
    "        os.remove('RunDynamic_Single.tcl')\n",
    "        acc_time += (f-s)\n",
    "        #print('Estimate remaining time %.3fs!'%(acc_time/(GM_ID - start_ID)*(finish_ID - GM_ID)))\n",
    "    else: \n",
    "        print('GM Pair %s has failed'%str(GM_ID))\n",
    "        break\n",
    "\n",
    "finish_time = time.time()\n",
    "print('The total runtime is %.3f minutes' %(int(finish_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing Dyanmic Analysis results\n",
    "\n",
    "Execute the following lines of only after all the dynamic analyses have been completed for all the hazard levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumGM = np.array([50, 47, 47, 48, 47])\n",
    "\n",
    "# CollapseCriteria = 0.1\n",
    "# DemolitionCriteria = 0.01\n",
    "\n",
    "# HazardLevel = np.array([0.403, 0.975, 1.307, 1.676, 2.237])\n",
    "\n",
    "# dynamicDirectory = os.path.join(cwd, *['BuildingModels',BuildingList[0],'DynamicAnalysis'])\n",
    "\n",
    "# sdr = extractedps.ExtractSDR(dynamicDirectory, HazardLevel, NumGM, numFloors)\n",
    "# rdr = extractedps.ExtractRDR(dynamicDirectory, HazardLevel, NumGM, NumStory)\n",
    "# gmDirectory = r'C:\\Users\\Laxman\\Desktop\\Python Tool\\BuildingModels\\GM_sets\\BoelterHall'\n",
    "# PGA = extractedps.ExtractPGA(gmDirectory, HazardLevel, NumGM)\n",
    "# pfa = extractedps.ExtractPFA(dynamicDirectory, HazardLevel, NumGM, NumStory, PGA, g = 386.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for now I'm importing an example EDP data from another example for demonstration purposes\n",
    "pfa = pd.read_csv(os.path.join(resultDirectory, 'PFA.csv'), header=None)\n",
    "sdr = pd.read_csv(os.path.join(resultDirectory,'SDR.csv'), header=None)\n",
    "rdr = pd.read_csv(os.path.join(resultDirectory,'RDR.csv'), header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess input data for pelicun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = []\n",
    "median = []\n",
    "log_std = []\n",
    "#1-PFA-0-1\n",
    "for stripe in pfa[0].unique():\n",
    "    churn_df = pfa[pfa[0]==stripe]\n",
    "    story_name = 0 \n",
    "    for story in churn_df.columns:\n",
    "        for uniq_dir in pfa[1].unique():\n",
    "            if story >=3:\n",
    "                story_name = story - 3\n",
    "                index_name.append('%s-PFA-%s-%s'%(stripe, story_name, uniq_dir))\n",
    "                median.append(pfa[(pfa[0]==stripe) & (pfa[1]==uniq_dir)][story].median())\n",
    "                log_std.append(pfa[(pfa[0]==stripe) & (pfa[1]==uniq_dir)][story].std())\n",
    "d = {\n",
    "    'idx': index_name, \n",
    "    'median': median, \n",
    "    'log_std': log_std\n",
    "}\n",
    "df_pfa = pd.DataFrame(d)\n",
    "df_pfa = df_pfa.set_index('idx')\n",
    "\n",
    "## PID\n",
    "index_name = []\n",
    "median = []\n",
    "log_std = []\n",
    "#1-PID-0-1\n",
    "for stripe in sdr[0].unique():\n",
    "    churn_df = sdr[sdr[0]==stripe]\n",
    "    story_name = 0 \n",
    "    for story in churn_df.columns:\n",
    "        for uniq_dir in sdr[1].unique():\n",
    "            if story >=3:\n",
    "                story_name = story - 2\n",
    "                index_name.append('%s-PID-%s-%s'%(stripe, story_name, uniq_dir))\n",
    "                median.append(sdr[(sdr[0]==stripe) & (sdr[1]==uniq_dir)][story].median())\n",
    "                log_std.append(sdr[(sdr[0]==stripe) & (sdr[1]==uniq_dir)][story].std())\n",
    "d = {\n",
    "    'idx': index_name, \n",
    "    'median': median, \n",
    "    'log_std': log_std\n",
    "}\n",
    "df_sdr = pd.DataFrame(d)\n",
    "df_sdr = df_sdr.set_index('idx')\n",
    "\n",
    "## combine two dfs \n",
    "df_comb = pd.concat([df_pfa, df_sdr])\n",
    "df_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "sample_size = 10000\n",
    "delta_y = 0.0075\n",
    "stripe = '3' # this is the hazard level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pelicun.base import set_options, convert_to_MultiIndex\n",
    "# from pelicun.assessment import Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare demand input\n",
    "raw_demands = convert_to_MultiIndex(df_comb, axis=0)\n",
    "raw_demands.index.names = ['stripe','type','loc','dir']\n",
    "\n",
    "# prepare the demand input for pelicun\n",
    "stripe_demands = raw_demands.loc[stripe,:]\n",
    "\n",
    "# units - - - - - - - - - - - - - - - - - - - - - - - -  \n",
    "stripe_demands.insert(0, 'Units',\"\")\n",
    "stripe_demands.loc['PFA','Units'] = 'g'\n",
    "stripe_demands.loc['PID','Units'] = 'rad'\n",
    "\n",
    "# distribution family  - - - - - - - - - - - - - - - - -  \n",
    "stripe_demands.insert(1, 'Family',\"\")\n",
    "stripe_demands['Family'] = 'lognormal'\n",
    "\n",
    "# distribution parameters  - - - - - - - - - - - - - - -\n",
    "stripe_demands.rename(columns = {'median': 'Theta_0'}, inplace=True)\n",
    "stripe_demands.rename(columns = {'log_std': 'Theta_1'}, inplace=True)\n",
    "\n",
    "# prepare a correlation matrix that represents perfect correlation\n",
    "ndims = stripe_demands.shape[0]\n",
    "demand_types = stripe_demands.index \n",
    "\n",
    "perfect_CORR = pd.DataFrame(\n",
    "    np.ones((ndims, ndims)),\n",
    "    columns = demand_types,\n",
    "    index = demand_types)\n",
    "\n",
    "# prepare additional fragility and consequence data ahead of time\n",
    "cmp_marginals = pd.read_csv('CMP_marginals.csv', index_col=0)\n",
    "\n",
    "# add missing data to P58 damage model\n",
    "P58_data = PAL.get_default_data('fragility_DB_FEMA_P58_2nd')\n",
    "cmp_list = cmp_marginals.index.unique().values[:-3]\n",
    "\n",
    "# now take those components that are incomplete, and add the missing information\n",
    "additional_fragility_db = P58_data.loc[cmp_list,:].loc[P58_data.loc[cmp_list,'Incomplete'] == 1].sort_index()\n",
    "\n",
    "# D2022.013a, 023a, 023b - Heating, hot water piping and bracing\n",
    "# dispersion values are missing, we use 0.5\n",
    "additional_fragility_db.loc[['D.20.22.013a','D.20.22.023a','D.20.22.023b'],\n",
    "                            [('LS1','Theta_1'),('LS2','Theta_1')]] = 0.5\n",
    "\n",
    "# D2031.013b - Sanitary Waste piping\n",
    "# dispersion values are missing, we use 0.5\n",
    "additional_fragility_db.loc['D.20.31.013b',('LS1','Theta_1')] = 0.5\n",
    "\n",
    "# D2061.013b - Steam piping\n",
    "# dispersion values are missing, we use 0.5\n",
    "additional_fragility_db.loc['D.20.61.013b',('LS1','Theta_1')] = 0.5\n",
    "\n",
    "# D3031.013i - Chiller\n",
    "# use a placeholder of 3.0|0.5\n",
    "additional_fragility_db.loc['D.30.31.013i',('LS1','Theta_0')] = 3.0\n",
    "additional_fragility_db.loc['D.30.31.013i',('LS1','Theta_1')] = 0.5\n",
    "\n",
    "# D3031.023i - Cooling Tower\n",
    "# use a placeholder of 3.0|0.5\n",
    "additional_fragility_db.loc['D.30.31.023i',('LS1','Theta_0')] = 3.0\n",
    "additional_fragility_db.loc['D.30.31.023i',('LS1','Theta_1')] = 0.5\n",
    "\n",
    "# D3052.013i - Air Handling Unit\n",
    "# use a placeholder of 3.0|0.5\n",
    "additional_fragility_db.loc['D.30.52.013i',('LS1','Theta_0')] = 3.0\n",
    "additional_fragility_db.loc['D.30.52.013i',('LS1','Theta_1')] = 0.5\n",
    "\n",
    "# prepare the extra damage models for collapse and irreparable damage\n",
    "additional_fragility_db.loc[\n",
    "    'excessiveRID', [('Demand','Directional'),\n",
    "                    ('Demand','Offset'),\n",
    "                    ('Demand','Type'), \n",
    "                    ('Demand','Unit')]] = [1, 0, 'Residual Interstory Drift Ratio', 'rad']   \n",
    "\n",
    "additional_fragility_db.loc[\n",
    "    'excessiveRID', [('LS1','Family'),\n",
    "                    ('LS1','Theta_0'),\n",
    "                    ('LS1','Theta_1')]] = ['lognormal', 0.01, 0.3]   \n",
    "\n",
    "additional_fragility_db.loc[\n",
    "    'irreparable', [('Demand','Directional'),\n",
    "                    ('Demand','Offset'),\n",
    "                    ('Demand','Type'), \n",
    "                    ('Demand','Unit')]] = [1, 0, 'Peak Spectral Acceleration|1.13', 'g']   \n",
    "\n",
    "additional_fragility_db.loc[\n",
    "    'irreparable', ('LS1','Theta_0')] = 1e10\n",
    "\n",
    "additional_fragility_db.loc[\n",
    "    'collapse', [('Demand','Directional'),\n",
    "                 ('Demand','Offset'),\n",
    "                 ('Demand','Type'), \n",
    "                 ('Demand','Unit')]] = [1, 0, 'Peak Spectral Acceleration|1.13', 'g']   \n",
    "\n",
    "additional_fragility_db.loc[\n",
    "    'collapse', [('LS1','Family'),\n",
    "                 ('LS1','Theta_0'),\n",
    "                 ('LS1','Theta_1')]] = ['lognormal', 1.35, 0.5]  \n",
    "\n",
    "# Now we can set the incomplete flag to 0 for these components\n",
    "additional_fragility_db['Incomplete'] = 0\n",
    "\n",
    "# create the additional consequence models\n",
    "additional_consequences = pd.DataFrame(\n",
    "    columns = pd.MultiIndex.from_tuples([\n",
    "        ('Incomplete',''), ('Quantity','Unit'), ('DV', 'Unit'), ('DS1', 'Theta_0')]),\n",
    "    index=pd.MultiIndex.from_tuples([\n",
    "        ('replacement','Cost'), ('replacement','Time')])\n",
    ")\n",
    "\n",
    "additional_consequences.loc[('replacement', 'Cost')] = [0, '1 EA', 'USD_2011', 21600000]\n",
    "additional_consequences.loc[('replacement', 'Time')] = [0, '1 EA', 'worker_day', 12500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate demand samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a pelicun Assessment\n",
    "PAL = Assessment({\"PrintLog\": True, \"Seed\": 415,})\n",
    "\n",
    "# load the demand model\n",
    "PAL.demand.load_model({'marginals': stripe_demands,\n",
    "                       'correlation': perfect_CORR})\n",
    "\n",
    "# generate samples\n",
    "PAL.demand.generate_sample({\"SampleSize\": sample_size})\n",
    "\n",
    "# add residual drift and Sa\n",
    "demand_sample = PAL.demand.save_sample()\n",
    "\n",
    "RID = PAL.demand.estimate_RID(demand_sample['PID'], {'yield_drift': delta_y})\n",
    "demand_sample_ext = pd.concat([demand_sample, RID], axis=1)\n",
    "\n",
    "Sa_vals = [0.158, 0.387, 0.615, 0.843, 1.071, 1.299, 1.528, 1.756]\n",
    "demand_sample_ext[('SA_1.13',0,1)] = Sa_vals[int(stripe)-1]\n",
    "\n",
    "# add units to the data \n",
    "demand_sample_ext.T.insert(0, 'Units',\"\")\n",
    "\n",
    "# PFA and SA are in \"g\" in this example, while PID and RID are \"rad\"\n",
    "demand_sample_ext.loc['Units', ['PFA', 'SA_1.13']] = 'g'\n",
    "demand_sample_ext.loc['Units',['PID', 'RID']] = 'rad'\n",
    "\n",
    "PAL.demand.load_sample(demand_sample_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify number of stories\n",
    "PAL.stories = 4\n",
    "\n",
    "# load component definitions\n",
    "cmp_marginals = pd.read_csv('CMP_marginals.csv', index_col=0)\n",
    "PAL.asset.load_cmp_model({'marginals': cmp_marginals})\n",
    "\n",
    "# generate sample\n",
    "PAL.asset.generate_cmp_sample(sample_size)\n",
    "\n",
    "# load the models into pelicun\n",
    "PAL.damage.load_damage_model([\n",
    "    additional_fragility_db,  # This is the extra fragility data we've just created\n",
    "    'PelicunDefault/fragility_DB_FEMA_P58_2nd.csv' # and this is a table with the default P58 data    \n",
    "])\n",
    "\n",
    "# prescribe the damage process\n",
    "dmg_process = {\n",
    "    \"1_collapse\": {\n",
    "        \"DS1\": \"ALL_NA\"\n",
    "    },\n",
    "    \"2_excessiveRID\": {\n",
    "        \"DS1\": \"irreparable_DS1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# calculate damages\n",
    "PAL.damage.calculate(dmg_process=dmg_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the loss map\n",
    "drivers = [f'DMG-{cmp}' for cmp in cmp_marginals.index.unique()]\n",
    "drivers = drivers[:-3]+drivers[-2:]\n",
    "\n",
    "loss_models = cmp_marginals.index.unique().tolist()[:-3] +['replacement',]*2\n",
    "\n",
    "loss_map = pd.DataFrame(loss_models, columns=['BldgRepair'], index=drivers)\n",
    "\n",
    "# load the loss model\n",
    "PAL.bldg_repair.load_model(\n",
    "    [additional_consequences,\n",
    "     \"PelicunDefault/bldg_repair_DB_FEMA_P58_2nd.csv\"], \n",
    "    loss_map)\n",
    "\n",
    "# perform the calculation\n",
    "PAL.bldg_repair.calculate()\n",
    "\n",
    "# get the aggregate losses\n",
    "agg_DF = PAL.bldg_repair.aggregate_losses()\n",
    "\n",
    "agg_DF.describe([0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lossModule.driverPelicun_E2E import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_index = 0\n",
    "main(building_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ATC-138 Functional Recovery Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "from lossModule.driverATC138_E2E import main_hazard_agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_hazard_agnostic(building_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
